#!/bin/bash
function error {
  echo "ERROR: $1" >&2
  log "$1"
  echo "Terminating abnormally." >&2
  log "Terminating abnormally."
  exit 1
}

function warn {
  echo "WARNING: $1" >&2
  log "$1"
}

function check_for_bin {
  if ! which $1 >/dev/null; then
    error "$1 not found on path."
  fi
}

function log {
  if ! [ -z $BACKUP_VERBOSE ]; then
    echo "LOG: $1"
  fi
  logger -t BCPCBackup "$1"
}

# path to base directory to store backups is expected as an argument to the script
if [[ $1 == "" ]]; then
  error "You must supply the base directory to store backups as the first argument to this script."
fi
# also supply word daily, weekly or monthly to drop backup in particular frequency directory
TIME_PERIODS=( daily weekly monthly )
VALID_TIME_PERIOD_FOUND=0
for TIME_PERIOD in ${TIME_PERIODS[@]}; do
  if [[ $2 =~ $TIME_PERIOD ]]; then
    VALID_TIME_PERIOD_FOUND=1
  fi
done
if [ $VALID_TIME_PERIOD_FOUND -eq 0 ]; then
  error "You must supply daily/weekly/monthly as the second argument to this script."
fi

log "Backup mode $2 requested."

# verify that base directory is RWX for this user
if ! [[ -r $1 && -w $1 && -x $1 ]]; then
  error "User $USER does not have full access to $1."
fi

DATE=$(date +%Y%m%d)

log "Backing up for date $DATE."

BACKUP_PATH=$1/$2/$DATE
if [ ! -d $BACKUP_PATH ]; then
  mkdir -p $BACKUP_PATH
  mkdir -p $BACKUP_PATH/main_db
  <% if @monitoring_servers.length > 0 %>
  mkdir -p $BACKUP_PATH/monitoring_db
  <% end %>
else
  warn "Directory $BACKUP_PATH already exists, attempting to continue."
fi

# perform backup of MySQL databases from the host in ~/.my.cnf
MYSQLDUMP=mysqldump
check_for_bin $MYSQLDUMP

MYSQL=mysql
check_for_bin $MYSQL

# .my.main.cnf (and .my.monitoring.conf if monitoring is set up)
# is expected to exist in the following format:
# [client]
# host=xxx
# user=xxx
# password=xxx
if [ ! -f $HOME/.my.main.cnf ]; then
  error "$HOME/.my.main.cnf not found."
fi
<% if @monitoring_servers.length > 0 %>
if [ ! -f $HOME/.my.monitoring.cnf ]; then
  error "$HOME/.my.monitoring.cnf not found."
fi
<% end %>

# get list of databases from MySQL
MAIN_DATABASES_RAW=$(mysql --defaults-file=$HOME/.my.main.cnf --batch --skip-column-names -e "SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.schemata WHERE SCHEMA_NAME != 'information_schema' AND SCHEMA_NAME != 'performance_schema' AND SCHEMA_NAME != 'test'")
if [ $? -ne 0 ]; then
  log "WARNING: unable to obtain information for main cluster databases."
fi

MAIN_DATABASES=( $MAIN_DATABASES_RAW )
for DATABASE in ${MAIN_DATABASES[@]}; do
  DB_BACKUP_PATH=$BACKUP_PATH/main_db/$DATABASE.sql.gz
  if [ ! -f $DB_BACKUP_PATH ]; then
    $MYSQLDUMP --defaults-file=$HOME/.my.main.cnf --single-transaction --events $DATABASE | gzip > $DB_BACKUP_PATH
    log "Backed up database $DATABASE to $DB_BACKUP_PATH."
  else
    error "File $DB_BACKUP_PATH already exists, refusing to overwrite."
  fi
done

<% if @monitoring_servers.length > 0 %>
# if we have monitoring servers to back up, do the same thing for them as well
MONITORING_DATABASES_RAW=$(mysql --defaults-file=$HOME/.my.monitoring.cnf --batch --skip-column-names -e "SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.schemata WHERE SCHEMA_NAME != 'information_schema' AND SCHEMA_NAME != 'performance_schema' AND SCHEMA_NAME != 'test'")
if [ $? -ne 0 ]; then
  log "WARNING: unable to obtain information for monitoring cluster databases."
fi

MONITORING_DATABASES=( $MONITORING_DATABASES_RAW )
for DATABASE in ${MONITORING_DATABASES[@]}; do
  DB_BACKUP_PATH=$BACKUP_PATH/monitoring_db/$DATABASE.sql.gz
  if [ ! -f $DB_BACKUP_PATH ]; then
    $MYSQLDUMP --defaults-file=$HOME/.my.monitoring.cnf --single-transaction --events $DATABASE | gzip > $DB_BACKUP_PATH
    log "Backed up database $DATABASE to $DB_BACKUP_PATH."
  else
    error "File $DB_BACKUP_PATH already exists, refusing to overwrite."
  fi
done
<% end %>

# back up Chef data bag
KNIFE=knife
check_for_bin $KNIFE

# ~/.chef/knife.rb must exist
if [ ! -f $HOME/.chef/knife.rb ]; then
  error "$HOME/.chef/knife.rb not found."
fi

CHEF_ENVS_RAW=$(knife data bag show configs)
CHEF_ENVS=( $CHEF_ENVS_RAW )
for CHEF_ENV in ${CHEF_ENVS[@]}; do
  DATABAG_BACKUP_PATH=$BACKUP_PATH/$CHEF_ENV-databag.json
  if [ ! -f $DATABAG_BACKUP_PATH ]; then
    $KNIFE data bag show configs -f json $CHEF_ENV > $DATABAG_BACKUP_PATH 2>/dev/null
    log "Backed up data bag for $CHEF_ENV to $DATABAG_BACKUP_PATH."
  else
    error "File $DATABAG_BACKUP_PATH already exists, refusing to overwrite."
  fi

  ENVIRONMENT_BACKUP_PATH=$BACKUP_PATH/$CHEF_ENV-environment.json
  if [ ! -f $ENVIRONMENT_BACKUP_PATH ]; then
    $KNIFE environment show -f json $CHEF_ENV > $ENVIRONMENT_BACKUP_PATH 2>/dev/null
    log "Backed up environment for $CHEF_ENV to $ENVIRONMENT_BACKUP_PATH."
  else
    error "File $ENVIRONMENT_BACKUP_PATH already exists, refusing to overwrite."
  fi
done

# prune old backups for currently given retention ($2)

# per original JIRA ticket EN-203, retention period is at least last 7 dailies
# and last 12 monthlies; extending to also have a weekly schedule that retains last 5
# instead of wackity find -atime/-ctime stuff, we can rely on lexical sort here
# to prune the oldest backups
case $2 in
  daily)
    BACKUPS_TO_KEEP=7
    ;;
  weekly)
    BACKUPS_TO_KEEP=5
    ;;
  monthly)
    BACKUPS_TO_KEEP=12
    ;;
esac

BACKUPS_TO_PRUNE_RAW=$(ls -1 $1/$2 | head -n -$BACKUPS_TO_KEEP)
BACKUPS_TO_PRUNE=( $BACKUPS_TO_PRUNE_RAW )

for BACKUP_TO_PRUNE in ${BACKUPS_TO_PRUNE[@]}; do
  BACKUP_DIR=$1/$2/$BACKUP_TO_PRUNE
  if [ -d $BACKUP_DIR ]; then
    rm -rf $BACKUP_DIR
    log "Purged backup directory $BACKUP_DIR."
  else
    warn "Got request to delete nonexistent directory $BACKUP_DIR."
  fi
done

# ding!
log "Backup for $DATE complete."
